{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training Magnification Model",
   "id": "1a2fc4960022699f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setting",
   "id": "c799863b6dabdf8d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-22T12:57:47.694113Z",
     "start_time": "2025-06-22T12:57:39.239193Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "video_path = \"video/speed80.mp4\"\n",
    "output_dir = \"data/frames_sample/\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cut Video into Image for Each Frame",
   "id": "6254af3481597aa9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T13:02:54.588649Z",
     "start_time": "2025-06-22T12:57:47.730447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from creating_dataset import *\n",
    "\n",
    "extract_frames_from_video(video_path, output_dir, prefix=\"sample\", every_nth=1)"
   ],
   "id": "c7609539b68e06ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting frames from video/speed80.mp4: 100%|██████████| 3630/3630 [05:06<00:00, 11.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 3630 frames to: data/frames_sample/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Creating Xa and Xb Image pairs",
   "id": "e3ca2322f90f5bc1"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-22T13:02:54.982478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "frame_dir = \"data/frames_sample\"\n",
    "xa_dir = \"data/training_data/L/Xa\"\n",
    "xb_dir = \"data/training_data/L/Xb\"\n",
    "\n",
    "prepare_xa_xb_pairs(frame_dir, xa_dir, xb_dir, step=1)"
   ],
   "id": "698a0d671c479cd7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Xa/Xb pairs:  26%|██▌       | 948/3629 [18:08<49:43,  1.11s/it]  "
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Creating Magnified Y Data within Xa and Xb",
   "id": "d75c8699ddb4d722"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:03:28.893875Z",
     "start_time": "2025-06-14T07:38:25.326141Z"
    }
   },
   "cell_type": "code",
   "source": "generate_Y_with_optical_flow(xa_dir, xb_dir, \"data/training_data/L/Y\", sf=50.0)",
   "id": "1cf0331a657b9ce7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Y with Optical Flow: 100%|██████████| 3629/3629 [2:25:03<00:00,  2.40s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 3629 warped Y images using Optical Flow to data/training_data/L/Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Structure",
   "id": "68c0e5079f5f99f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:03:29.478972Z",
     "start_time": "2025-06-14T10:03:29.012077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from magnification_model import *\n",
    "\n",
    "model = MagnificationModel().to(device)\n",
    "\n",
    "input_Xa = torch.randn(1, 3, 224, 224).to(device)\n",
    "input_Xb = torch.randn(1, 3, 224, 224).to(device)\n",
    "SF = torch.tensor(20.0).to(device)\n",
    "\n",
    "summary(model, input_data=(input_Xa, input_Xb, SF), col_names=[\"input_size\", \"output_size\", \"num_params\"], depth=3)"
   ],
   "id": "bdb3f60b20adb9a5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "MagnificationModel                       [1, 3, 224, 224]          [1, 3, 224, 224]          --\n",
       "├─Encoder: 1-1                           [1, 3, 224, 224]          [1, 32, 112, 112]         --\n",
       "│    └─Sequential: 2-1                   [1, 3, 224, 224]          [1, 32, 112, 112]         --\n",
       "│    │    └─Conv2d: 3-1                  [1, 3, 224, 224]          [1, 16, 224, 224]         2,368\n",
       "│    │    └─ReLU: 3-2                    [1, 16, 224, 224]         [1, 16, 224, 224]         --\n",
       "│    │    └─Conv2d: 3-3                  [1, 16, 224, 224]         [1, 32, 112, 112]         4,640\n",
       "│    │    └─ReLU: 3-4                    [1, 32, 112, 112]         [1, 32, 112, 112]         --\n",
       "│    └─Sequential: 2-2                   [1, 32, 112, 112]         [1, 32, 112, 112]         --\n",
       "│    │    └─ResidualBlock: 3-5           [1, 32, 112, 112]         [1, 32, 112, 112]         18,496\n",
       "│    │    └─ResidualBlock: 3-6           [1, 32, 112, 112]         [1, 32, 112, 112]         18,496\n",
       "│    │    └─ResidualBlock: 3-7           [1, 32, 112, 112]         [1, 32, 112, 112]         18,496\n",
       "│    └─Sequential: 2-3                   [1, 32, 112, 112]         [1, 32, 112, 112]         36,992\n",
       "│    │    └─Conv2d: 3-8                  [1, 32, 112, 112]         [1, 32, 112, 112]         9,248\n",
       "│    │    └─ReLU: 3-9                    [1, 32, 112, 112]         [1, 32, 112, 112]         --\n",
       "│    └─Sequential: 2-9                   --                        --                        (recursive)\n",
       "│    │    └─Sequential: 3-10             [1, 32, 112, 112]         [1, 32, 112, 112]         36,992\n",
       "│    └─Sequential: 2-5                   [1, 32, 112, 112]         [1, 32, 56, 56]           36,992\n",
       "│    │    └─Conv2d: 3-11                 [1, 32, 112, 112]         [1, 32, 56, 56]           9,248\n",
       "│    │    └─ReLU: 3-12                   [1, 32, 56, 56]           [1, 32, 56, 56]           --\n",
       "│    │    └─Sequential: 3-13             [1, 32, 56, 56]           [1, 32, 56, 56]           (recursive)\n",
       "├─Encoder: 1-2                           [1, 3, 224, 224]          [1, 32, 112, 112]         (recursive)\n",
       "│    └─Sequential: 2-6                   [1, 3, 224, 224]          [1, 32, 112, 112]         (recursive)\n",
       "│    │    └─Conv2d: 3-14                 [1, 3, 224, 224]          [1, 16, 224, 224]         (recursive)\n",
       "│    │    └─ReLU: 3-15                   [1, 16, 224, 224]         [1, 16, 224, 224]         --\n",
       "│    │    └─Conv2d: 3-16                 [1, 16, 224, 224]         [1, 32, 112, 112]         (recursive)\n",
       "│    │    └─ReLU: 3-17                   [1, 32, 112, 112]         [1, 32, 112, 112]         --\n",
       "│    └─Sequential: 2-7                   [1, 32, 112, 112]         [1, 32, 112, 112]         (recursive)\n",
       "│    │    └─ResidualBlock: 3-18          [1, 32, 112, 112]         [1, 32, 112, 112]         (recursive)\n",
       "│    │    └─ResidualBlock: 3-19          [1, 32, 112, 112]         [1, 32, 112, 112]         (recursive)\n",
       "│    │    └─ResidualBlock: 3-20          [1, 32, 112, 112]         [1, 32, 112, 112]         (recursive)\n",
       "│    └─Sequential: 2-8                   [1, 32, 112, 112]         [1, 32, 112, 112]         (recursive)\n",
       "│    │    └─Conv2d: 3-21                 [1, 32, 112, 112]         [1, 32, 112, 112]         (recursive)\n",
       "│    │    └─ReLU: 3-22                   [1, 32, 112, 112]         [1, 32, 112, 112]         --\n",
       "│    └─Sequential: 2-9                   --                        --                        (recursive)\n",
       "│    │    └─Sequential: 3-23             [1, 32, 112, 112]         [1, 32, 112, 112]         (recursive)\n",
       "│    └─Sequential: 2-10                  [1, 32, 112, 112]         [1, 32, 56, 56]           (recursive)\n",
       "│    │    └─Conv2d: 3-24                 [1, 32, 112, 112]         [1, 32, 56, 56]           (recursive)\n",
       "│    │    └─ReLU: 3-25                   [1, 32, 56, 56]           [1, 32, 56, 56]           --\n",
       "│    │    └─Sequential: 3-26             [1, 32, 56, 56]           [1, 32, 56, 56]           (recursive)\n",
       "├─Manipulator: 1-3                       [1, 32, 112, 112]         [1, 32, 112, 112]         36,992\n",
       "├─Decoder: 1-4                           [1, 32, 56, 56]           [1, 3, 224, 224]          --\n",
       "│    └─Upsample: 2-11                    [1, 32, 56, 56]           [1, 32, 112, 112]         --\n",
       "│    └─Sequential: 2-12                  [1, 64, 112, 112]         [1, 64, 112, 112]         --\n",
       "│    │    └─Conv2d: 3-27                 [1, 64, 112, 112]         [1, 64, 112, 112]         36,928\n",
       "│    │    └─ReLU: 3-28                   [1, 64, 112, 112]         [1, 64, 112, 112]         --\n",
       "│    │    └─BatchNorm2d: 3-29            [1, 64, 112, 112]         [1, 64, 112, 112]         128\n",
       "│    └─Sequential: 2-13                  [1, 64, 112, 112]         [1, 64, 112, 112]         --\n",
       "│    │    └─ResidualBlock: 3-30          [1, 64, 112, 112]         [1, 64, 112, 112]         73,856\n",
       "│    │    └─ResidualBlock: 3-31          [1, 64, 112, 112]         [1, 64, 112, 112]         73,856\n",
       "│    │    └─ResidualBlock: 3-32          [1, 64, 112, 112]         [1, 64, 112, 112]         73,856\n",
       "│    │    └─ResidualBlock: 3-33          [1, 64, 112, 112]         [1, 64, 112, 112]         73,856\n",
       "│    │    └─ResidualBlock: 3-34          [1, 64, 112, 112]         [1, 64, 112, 112]         73,856\n",
       "│    └─Sequential: 2-14                  [1, 64, 112, 112]         [1, 32, 224, 224]         --\n",
       "│    │    └─ConvTranspose2d: 3-35        [1, 64, 112, 112]         [1, 32, 224, 224]         32,800\n",
       "│    │    └─ReLU: 3-36                   [1, 32, 224, 224]         [1, 32, 224, 224]         --\n",
       "│    └─Conv2d: 2-15                      [1, 32, 224, 224]         [1, 3, 224, 224]          4,707\n",
       "│    └─Sigmoid: 2-16                     [1, 3, 224, 224]          [1, 3, 224, 224]          --\n",
       "===================================================================================================================\n",
       "Total params: 672,803\n",
       "Trainable params: 672,803\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 10.17\n",
       "===================================================================================================================\n",
       "Input size (MB): 1.20\n",
       "Forward/backward pass size (MB): 189.06\n",
       "Params size (MB): 2.25\n",
       "Estimated Total Size (MB): 192.51\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Train\n",
    "Load the model with `MagnificationModel()`\n",
    "Load the device with cuda if it is possible\n",
    "\n",
    "`train()` variable:\n",
    "- model: loaded magnification model\n",
    "- Xa: input image at index i\n",
    "- Xb: input image at index i+1\n",
    "- Y: magnified image(GT)\n",
    "- device: cuda or cpu\n",
    "- num_epochs: number of epoch\n",
    "- batch_size: size of batch\n",
    "- save_path: the path to save the model\n"
   ],
   "id": "a121497cd0604b60"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from training import train\n",
    "\n",
    "model = MagnificationModel()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train(\n",
    "    model=model,\n",
    "    xa_dir=\"data/training_data/L/Xa\",\n",
    "    xb_dir=\"data/training_data/L/Xb\",\n",
    "    y_dir=\"data/training_data/L/Y\",\n",
    "    device=device,\n",
    "    num_epochs=15,\n",
    "    batch_size=4,\n",
    "    save_path=\"model/best_magnification_model_L.pth\"\n",
    ")\n"
   ],
   "id": "c4d22ad473b7d5ba"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
